---

id: chapter-1
title: 1. From AI to Agentic Applications
sidebar\_label: Chapter 1
last\_update:
date: "09-01-2025"
------------------

### В этой главе

* Основы ИИ
* ИИ-агенты и агентные приложения
* Первый контакт с API ИИ и ИИ-агентами

Каждое приложение станет агентным приложением. От кодирующих агентов, которые запускаются локально в вашем IDE или терминале, до корпоративных агентов, оркеструющих действия в распределённых средах — агентное приложение работает автономно и непрерывно в погоне за целью (рисунок 1.1).

<br />

![Figure 1.1](/img/chapter1/figure1.1.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.1: Агентное приложение действует автономно и непрерывно в погоне за целью
</div>

<br />

Агентные приложения состоят из ИИ-агентов, а ИИ-агенты состоят из API ИИ. Чтобы эффективно проектировать такие системы, нам нужно понимать их структуру и поведение снизу вверх. В этой главе мы начинаем с нижних уровней, чтобы понять, как токены, модели, обучение и инференс ограничивают то, что происходит на верхних уровнях.

## 1.1 Основы ИИ

Преобразование традиционных приложений в агентные приложения обеспечивается большими языковыми моделями (LLM). В отличие от прежних технологий ИИ, узких и доменно-специфичных, LLM — широкого, общего назначения: они способны рассуждать о целях и оркестровать сложные действия. Поэтому на протяжении всей книги мы будем рассматривать мир API ИИ, агентов и агентных приложений прежде всего через призму LLM.

\:::info Концептуальная рамка
Используя конкретные примеры от различных провайдеров ИИ, мы сосредотачиваемся на построении концептуальной рамки, которая отражает существенное поведение, общее для систем. Механика может различаться, но паттерны более высокого уровня остаются постоянными и дают надёжную основу для инженерии агентных приложений.
\:::

LLM строятся из четырёх фундаментальных компонентов: токены, модели, обучение и инференс (см. рисунок 1.2).

<br />

![Figure 1.2](/img/chapter1/figure1.2.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.2: Конвейер большой языковой модели и взаимосвязь между токенами, моделями, обучением и инференсом
</div>

<br />

Инженеры систем не реализуют эти низкоуровневые компоненты, но понимание этих основ, даже на концептуальном уровне, необходимо для построения надёжных и масштабируемых агентных приложений.

### 1.1.1 Токены

LLM работают с текстом: они обучаются на тексте, получают текст на вход и возвращают текст на выход. Однако LLM обрабатывают текст иначе, чем люди. Люди делят текст на символы или слова (см. рисунок 1.3).

<br />

![Figure 1.3](/img/chapter1/figure1.3.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.3: Текст, разделённый на символы или слова людьми для людей.
</div>

<br />

LLM, напротив, делят текст на токены, то есть числовые идентификаторы фрагментов текста (см. рисунок 1.4).

<br />

![Figure 1.4](/img/chapter1/figure1.4.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.4: Текст, разделённый на токены токенизатором GPT-4o, и их численные значения.
</div>

<br />

Разные токенизаторы присваивают разные числовые значения фрагментам текста. Для наших целей мы абстрагируем токенизацию до её сущностного интерфейса (см. листинг 1.1):

```typescript
// A Token is a numerical representation of a fragment of text
type Token = number

interface Tokenizer {
  // Abstract function to represent the translation of text into tokens
  function encode(String) : Token[]

  // Abstract function to represent the translation of tokens into text
  function decode(Token[]) : String
}
```

<div className="listing-description">
  Листинг 1.1: Абстрактное представление токенизатора как интерфейса с функциями encode и decode
</div>

Токенизатор поддерживает отображение от токенов к соответствующим фрагментам текста. Дополнительно он может определять специальные токены или управляющие токены (подобно управляющим символам, таким как carriage return в ASCII или Unicode). Множество всех токенов также называют алфавитом или словарём.

### 1.1.2 Модели

Модели — публичное лицо ИИ. Новые релизы от OpenAI, Anthropic и других провайдеров выходят с большим ожиданием, широко обсуждаются, хвалятся и критикуются. Сегодня релиз — культурное событие: демо становятся вирусными, а истории о неожиданном или разочаровывающем поведении быстро распространяются.

Под шумом хайпа модели удивительно прозаичны: упорядоченный набор параметров (см. листинг 1.2).

```typescript
// Type to represent a model parameter
type Param = number;

// Type to represent a model
type Model = Param[];

// Context window length
function length(model : Model) : number
```

<div className="listing-description">
  Листинг 1.2: Представление модели как массива параметров
</div>

У LLM от разных провайдеров есть две характеристические величины:

**Число параметров**: сколько параметров модель может выучить во время обучения. Это отражает, сколько информации модель может хранить *в целом*. Современные модели варьируются от миллиардов до триллионов параметров.

**Окно контекста**: сколько токенов модель может обработать во время инференса. Это отражает, сколько информации модель может учитывать *одновременно*. Современные модели варьируются от десятков тысяч до более чем 2 миллионов токенов.

По сути, эти параметры образуют гигантскую таблицу соответствий. Для любой последовательности токенов в пределах окна контекста модель выдаёт вектор вероятностей, присваивающий каждому токену из словаря вероятность быть следующим. Это единственная функция модели: по заданному контексту предсказывать следующий токен.

Миллиарды параметров кодируют шаблоны, выученные из обучающих данных. Эти шаблоны охватывают всё — от базовой грамматики до сложных стратегий рассуждения, фактических знаний и стилистических предпочтений. Вместе они определяют как способности модели, так и её ограничения.

\:::note Формализация
С использованием формализма вроде TLA+ (Темпоральная логика действий) мы можем формализовать модель так:

```tla
# The vocabulary of the Large Language Model
TOKENS == { ... }

# The context window length
LENGTH == 1000000

# A model maps each token sequence to a per-token probability
MODELS ==
  [ { s ∈ Seq(TOKENS) : Len(s) ≤ LENGTH } → [TOKENS → [0.0 .. 1.0]] ]
```

\:::

Модели поражают и внушают трепет из-за колоссальных ресурсов, требуемых при обучении, и возможностей, демонстрируемых при инференсе.

### 1.1.3 Обучение

Обучение — это функция создания или обновления модели, точнее, параметров модели, на основе набора данных (см. листинг 1.3).

```typescript
// Variable to represent the init, empty, or scratch model
const init: Model = [];

// Abstract function to represent training
function train(model: Model, dataset: Set<Token[]>): Model
```

<div className="listing-description">
  Листинг 1.3: Абстрактная сигнатура функции обучения
</div>

Есть два варианта обучения:

1. **Обучение с нуля (scratch model)**: выучить параметры модели, начиная с пустой модели. Требует много данных, вычислительных ресурсов и времени.

2. **Обучение от базовой модели (fine-tuning)**: выучить параметры, начиная с базовой модели. Требует меньше данных, ресурсов и времени.

\:::info Выбор моделирования

Мы могли бы моделировать создание и обновление модели как две разные функции. Однако, представляя обе как одну функцию, мы снижаем когнитивную нагрузку и устанавливаем отношения между моделями, все из которых коренятся в начальной (scratch) модели (см. рисунок 1.5).

\:::

<br />

![Figure 1.5](/img/chapter1/figure1.5.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.5: Отношения между моделями показывают, как все модели выводятся из начальной scratch-модели посредством обучения
</div>

<br />

\:::note Формализация
На обучение можно смотреть как на недетерминированный выбор модели в пространстве моделей. Здесь недетерминированный выбор полностью абстрагирует механики обучения.

```tla
# We abstract training by non-deterministically choosing a model in the
# model space
train(dataset) ==
  CHOOSE model ∈ MODELS : TRUE
```

\:::

Из-за значительных ресурсных требований обучение с нуля доступно в основном ИИ-лабораториям, тогда как дообучение подходит многим командам.

### 1.1.4 Инференс

Инференс — это применение модели к последовательности токенов для получения следующего токена (см. листинг 1.4).

```typescript
function infer(model : Model, context : Token[]) : Token
```

<div className="listing-description">
  Листинг 1.4: Абстрактная сигнатура функции инференса
</div>

Модели — детерминированные математические функции: при одинаковом вводе они всегда производят одно и то же распределение вероятностей. Однако вместо того чтобы всегда выбирать токен с наивысшей вероятностью, инференс выполняет выборку из распределения, используя стратегии вроде top-k. Эта контролируемая случайность делает ответы разнообразными и кажущимися творческими. Например, по подсказке «The capital of France is» инференс может (итеративно) выдать «Paris» или «the city of Paris».

\:::info Контролируемая случайность
Сэмплирование не является истинной случайностью. Оно опирается на генераторы псевдослучайных чисел, инициализируемые зерном (seed). При одинаковом зерне и одинаковом контексте инференс каждый раз даёт идентичный результат. Однако параметр seed часто не экспонируется в интерфейсах API, поэтому по умолчанию следует считать инференс случайным.
\:::

\:::note Формализация
infer выбирает top-k токенов, то есть токены с наибольшими вероятностями, и делает недетерминированный выбор

```tla
# We abstract over inference by non-deterministically choosing
# a next token of the 10 most likely tokens given the context
Infer(model, context) ==
  CHOOSE token ∈ TOPK(model[context], 10)
```

\:::

## 1.2 Модели и API ИИ

Базовые компоненты — токены, модели, обучение и инференс — комбинируются в практические API ИИ. Итеративно применяя инференс и предсказывая по одному токену, мы превращаем распределения вероятностей в связный текст. Разные подходы к обучению дают разные возможности API. Рассмотрим три типа моделей:

* Модели дополнения (completion, также «базовые модели»)
* Модели диалога (conversation, также «чат-модели»)
* Модели вызова инструментов (tool-calling)

<br />

![Figure 1.6](/img/chapter1/figure1.6.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.6: Типы моделей и их отношения по обучению/дообучению
</div>

### 1.2.1 Модели дополнения

Модели дополнения обучаются дополнять текст. Их обучающие данные — это последовательности токенов, обёрнутые в специальные маркеры границ:

* **BOS** — Beginning of Sequence. Отмечает начало последовательности.
* **EOS** — End of Sequence. Отмечает конец последовательности.

BOS и EOS — важные элементы обучения: они позволяют модели кодировать начала и окончания последовательностей. Так модели учатся генерировать завершённые, ограниченные ответы, а не продолжать бесконечно.

```
<BOS>
  The capital of France is Paris.
<EOS>
```

Модели дополнения дополняют текст, итеративно генерируя следующий токен, пока не встретят стоп-токен (см. листинг 1.5)

```typescript

// Assumes global tokenizer with BOS and EOS special tokens

function generate(model: Model, promptTokens: Token[]): Token[] {
  const answerTokens: Token[] = [];

  while (true) {
    const next = infer(model, [
      tokenizer.BOS,
      ...promptTokens,
      ...answerTokens
    ]);
    if (next == tokenizer.EOS) {
      break;
    }
    answerTokens.push(next);
  }

  return answerTokens;
}

function complete(model: Model, prompt: string): string {
  const promptTokens: Token[] = tokenizer.encode(prompt);
  const answerTokens: Token[] = generate(model, promptTokens);
  return tokenizer.decode(answerTokens);
}
```

<div className="listing-description">
  Листинг 1.5: Генерация токенов и завершение текста для базовых моделей
</div>

Об этом типе модели и её API генерации можно думать как о «машине дополнения» предложений: на вход подсказка, на выход — её дополнение.

```
prompt: The capital of France
answer: is Paris
```

Модели дополнения были первыми доступными LLM. Хотя они уступают современным моделям диалога и вызова инструментов, они остаются концептуальным фундаментом: каждое взаимодействие сводится к итеративному предсказанию токенов.

### 1.2.2 Модели диалога

Модели диалога — это модели дополнения, дообученные на завершение беседы с соблюдением инструкций. Их обучающие данные добавляют маркеры ролей, различающие системные инструкции и участников:

```
<BOS>
  <|BOT role=system|>
    You are a helpful assistant.
  <|EOT|>
  <|BOT role=user|>
    What is the capital of France?
  <|EOT|>
  <|BOT role=assistant|>
    The capital of France is Paris.
  <|EOT|>
<EOS>
```

Маркеры ролей — важный шаг вперёд: возникает структурированный протокол. Модель учится не просто дополнять текст, а участвовать в многоходовом диалоге, поддерживая контекст между собеседниками и следуя системным инструкциям.

Как и модели дополнения, модели диалога генерируют токены итеративно, пока не встретят стоп-токен (см. листинг 1.6):

```typescript
type Turn = {
  role: "SYSTEM" | "USER" | "ASSISTANT"
  text: string
}

function converse(model : Model, prompt: Turn[]) : Turn {
  const promptTokens: Token[] = prompt.flatMap(turn => [
    tokenizer.BOT(turn.role),
    ...tokenizer.encode(turn.text),
    tokenizer.EOT()
  ]);

  const answerTokens: Token[] = generate(model, promptTokens)

  // Parses response text to extract assistant's turn
  return Turn.parse(tokenizer.decode(answerTokens))
}
```

<div className="listing-description">
  Листинг 1.6: Функция диалога для чат-моделей с ходами, основанными на ролях
</div>

Об этом типе модели и её API генерации можно думать как о «машине дополнения» для бесед: на вход — подсказка, на выход — завершение ответа.

```
prompt: What is the capital of France?
answer: The capital of France is Paris.
```

Хотя модели диалога могут взаимодействовать с пользователями, они не могут взаимодействовать со средой. Модели вызова инструментов закрывают этот разрыв.

### 1.2.3 Модели вызова инструментов

Модели вызова инструментов расширяют модели диалога возможностью вызывать внешние функции. Их обучающие данные включают определения инструментов в системной подсказке и новую роль для ответов инструментов:

```
<BOS>
  <|BOT role=system|>
    You are a helpful assistant. You may call tools:
      - getWeather(location: string): returns current weather.
  <|EOT|>
  <|BOT role=user|>
    How's the weather in Paris?
  <|EOT|>
  <|BOT role=assistant|>
    tool:getWeather("Paris")
  <|EOT|>
  <|BOT role=tool|>
    28C sunny
  <|EOT|>
  <|BOT role=assistant|>
    The current weather in Paris is 28C and sunny.
  <|EOT|>
<EOS>
```

Модель учится распознавать, когда нужны внешние сведения или действия, и генерирует структурированные вызовы инструментов. Однако модель не исполняет инструменты напрямую — она производит инструкции, которые должен выполнить вызывающий, а затем вернуть результат модели в следующем шаге.

Об этом типе модели и её API генерации можно думать как о «машине дополнения» для бесед с доступом к инструментам для наблюдений или запуска действий:

```
prompt: How's the weather in Paris?
answer: tool:getWeather("Paris").
prompt: 28C sunny
answer: The current weather in Paris is 28C and sunny.
```

Хотя модели вызова инструментов могут генерировать ответы и инициировать вызовы функций, по сути они остаются генеративными, производя один вывод на каждый ввод.

## 1.3 ИИ-агенты

Агенты добавляют к генерации оркестрацию и управление состоянием: в отличие от статeless, одношаговых API ИИ, агенты — это stateful, многошаговые компоненты, способные устойчиво преследовать цель.

### 1.3.1 Агент

Определим агента A как кортеж из модели M, набора инструментов T и системной подсказки s:

```
A = (M, T, s)
```

Определим экземпляр агента Ai (также сессия или разговор) с идентификатором i как кортеж из модели M, инструментов T, системной подсказки s и истории h:

```
Ai = (M, T, s, h)
```

История h превращает абстрактное определение агента в экземпляр или исполнение агента. История структурирована как последовательность обменов:

```
h = [(u₁, a₁), (u₂, a₂), (u₃, a₃), (u₄, a₄), ...]
```

где u — сообщение пользователя, a — ответ агента.

Когда участвует вызов инструментов, история расширяется, чтобы включать вызовы инструментов (t) и их результаты (r):

```
h = [(u₁, a₁), (u₂, t₁), (r₁, a₂), (u₃, a₃), ...]
```

### 1.3.2 Цикл агента

ИИ-агенты организованы вокруг центрального оркестрационного цикла, который координирует API ИИ, пользователя и инструменты, управляя состоянием беседы. Этот цикл агента представляет основную инженерную задачу в агентных приложениях. Цикл отвечает за управление состоянием, координацию асинхронных и длительных операций, а также обработку восстановления при сбоях.

## 1.4 Агентные приложения

Агентные приложения варьируются от одноагентных систем до многоагентных, где агенты координируются с другими агентами. В многоагентных системах агенты могут вызывать других агентов, создавая динамические графы вызовов (см. рисунок 1.7).

<br />

![Figure 1.7](/img/chapter1/figure1.7.svg)

<div style={{textAlign: 'center', fontStyle: 'italic', marginTop: '-10px'}}>
  Рисунок 1.7: Многоагентные системы формируют динамические графы вызовов: агенты вызывают других агентов и инструменты
</div>

<br />

## 1.5 Первый контакт

Закрепив основы, давайте взаимодействовать с реальным API ИИ. В основном мы будем использовать OpenAI для примеров, хотя паттерны применимы и к другим провайдерам.

### 1.5.1 Базовый API

Листинг 1.7 иллюстрирует самое базовое взаимодействие с API. Мы передаём желаемую модель, контекст — историю беседы и текущую подсказку — и запрашиваем completion.

```typescript
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function main() {
  const completion = await openai.chat.completions.create({
    model: "gpt-5",
    messages: [{
      role: "user", content: "What is the capital of France?"
    }]
  });

  console.log(completion);
}

main();
```

<div className="listing-description">
  Листинг 1.7: Базовое взаимодействие с API OpenAI
</div>

API возвращает структурированный ответ (листинг 1.8):

```json {10}
{
  "id": "chatcmpl-C5rNhjKYS8nYoXdnZmTjK5T2FEsVX",
  "object": "chat.completion",
  "model": "gpt-5-2025-08-07",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Paris.",
        "refusal": null,
        "annotations": []
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "total_tokens": 23,
    "prompt_tokens": 12,
    "completion_tokens": 11
  }
}
```

<div className="listing-description">
  Листинг 1.8: Ответ ассистента
</div>

Однако чаще в этой книге нас интересует просто ответ ИИ (листинг 1.9)

```typescript
const answer : string? = completion.choices[0]?.message?.content;
```

<div className="listing-description">
  Листинг 1.9: Извлечение текстового содержимого ответа ассистента
</div>

### 1.5.2 Потоковый API

Многие API ИИ предлагают два режима работы: пакетный (возвращает ответ целиком) и потоковый (возвращает ответ постепенно, токен за токеном). Потоковый режим может улучшить пользовательский опыт: вместо ожидания пользователи видят, как ответ формируется в реальном времени, что придаёт естественное, разговорное ощущение и снижает воспринимаемую задержку (см. листинг 1.10).

```typescript
import OpenAI from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function main() {
  const stream = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [{
      role: "user", content: "Tell me about Paris"
    }],
    stream: true,
  });

  let answer = "";

  for await (const chunk of stream) {
    const content = chunk.choices?.[0]?.delta?.content;
    if (content) {
      process.stdout.write(content);
      answer += content;
    }
  }

}

main();
```

<div className="listing-description">
  Листинг 1.10: Потоковый API для ответов в реальном времени, токен за токеном
</div>

У потоков есть вызовы:

* **Эфемерность vs Долговечность.** Поток добавляет архитектурную сложность. Пока токены постепенно прибывают для отображения, приложению нужен полный ответ, чтобы обновить историю диалога и запустить зависимые операции. Это двойное требование — обрабатывать и эфемерный поток, и долговечный результат — усложняет дизайн системы, особенно когда разным компонентам нужны разные представления одного и того же ответа.

### 1.5.3 Вызов инструментов

Вызов инструментов расширяет модели диалога возможностью вызывать внешние функции, позволяя ИИ взаимодействовать с миром за пределами генерации текста посредством структурированных вызовов (см. листинг 1.11).

```typescript
import OpenAI from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const tools = [
  {
    type: "function",
    function: {
      name: "get_current_weather",
      description: "Get the current weather in a given location",
      parameters: {
        type: "object",
        properties: {
          location: {
            type: "string",
            description:
              "The city, state, and country, e.g. Berlin, Germany or San Francisco, CA, USA",
          },
        },
        required: ["location"],
      },
    },
  },
];

async function main() {
  const completion = await openai.chat.completions.create({
    model: "gpt-5",
    messages: [
      {
        role: "user",
        content: "What is the weather in Paris right now",
      },
    ],
    tools: tools,
  });

  console.log(JSON.stringify(completion));
}

main();

```

<div className="listing-description">
  Листинг 1.11: API вызова инструментов
</div>

API возвращает ответ, содержащий вызов инструмента (листинг 1.12):

```json
{
  "id": "chatcmpl-C76JQRfuc9HXpErPldbVyRuieZ8Lm",
  "object": "chat.completion",
  "created": 1755808596,
  "model": "gpt-5-2025-08-07",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_hQF9XaYtq8ZO6LJl6S3WctoU",
            "type": "function",
            "function": {
              "name": "get_current_weather",
              "arguments": "{\"location\":\"Paris, France\"}"
            }
          }
        ],
        "refusal": null,
        "annotations": []
      },
      "finish_reason": "tool_calls"
    }
  ],
}
```

<div className="listing-description">
  Листинг 1.12: Ответ ассистента
</div>

Вызов инструментов сопровождается вызовами (сложностями):

* **API не исполняет инструменты напрямую.** Вместо этого API возвращает структурированное представление намеренного вызова. Вызывающее приложение должно выполнить инструмент и вернуть результат.

* **Вызовы инструментов создают блокирующие зависимости.** Беседа не может продолжиться, пока результат инструмента не будет предоставлен в следующем ходе. Пропуск этого шага вызывает исключение.

Этот паттерн возлагает на приложение ответственность за исполнение инструментов, координацию и обработку сбоев, добавляя существенную сложность сверх управления генерацией текста.

### 1.5.4 Простой агент

Листинг 1.13 демонстрирует переход от API ИИ к ИИ-агенту. В то время как предыдущие примеры показывали изолированные, одношаговые взаимодействия, где каждый вызов API существовал самостоятельно, эта реализация показывает, как обёртка API ИИ в постоянный цикл превращает его в разговорного агента. Ключевая мысль — память: поддерживая историю беседы между взаимодействиями, мы превращаем stateless вызовы API в stateful диалог.

```typescript {15-17}
import OpenAI from "openai";
// peripherals.ts provides simple console I/O utilities
import { getUserInput, closeUserInput } from "./peripherals";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function main() {
  const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [{
    role: "system", content: "End your final answer with <EXIT>.",
  }];

  while (true) {
    let prompt = await getUserInput(
      "User (type 'exit' to quit):",
    );

    if (prompt.toLowerCase() === "exit") {
      break;
    }

    messages.push({role: "user", content: prompt});

    const completion = await openai.chat.completions.create({
      model: "gpt-4",
      messages: messages
    });

    const answer = completion.choices[0]?.message?.content;

    messages.push({role: "assistant", content: answer});

    console.log("Assistant:", answer);

    if (answer.includes("<EXIT>")) {
      break;
    }
  }

  closeUserInput();
}

main();
```

<div className="listing-description">
  Листинг 1.13: Простой разговорный агент с циклом взаимодействия
</div>

Эта минимальная реализация показывает основную архитектуру, лежащую в основе всех ИИ-агентов. Каждый агент должен решать фундаментальные вопросы:

* **Управление состоянием**: поддержание истории беседы между взаимодействиями. Здесь массив `messages` накапливает диалог, превращая stateless вызовы API в stateful беседу.

* **Управление идентичностью**: поддержание уникальной идентичности агента. Здесь управление идентичностью сведено к полаганию на выполняющийся процесс.

* **Управление жизненным циклом**: инициализация, выполнение, приостановка, возобновление и завершение. Здесь жизненный цикл ограничивается базовыми условиями завершения (пользовательский "exit", метка ИИ `<EXIT>`).

Хотя наш простой агент корректно работает, он выявляет фундаментальные проблемы, критичные при масштабировании. Агент проводит большую часть времени в простое, блокируясь на `getUserInput()`. Что важнее, тесная привязка процесса и агента создаёт хрупкость: если процесс падает, завершается или требует перезапуска, весь экземпляр агента исчезает, унося с собой весь контекст беседы.

### 1.5.5 К устойчивым агентам

Фундаментальный изъян архитектуры нашего простого агента — связывание экземпляра агента с экземпляром процесса. Эта связка создаёт непреодолимые проблемы в продуктивных системах:

**Кризис идентичности и состояния**: идентичность и память агента должны превышать по времени и месту субстрат, исполняющий агента. Если перезапуск системы или сбой уничтожают идентичность агента и накопленные знания, агент непригоден для сколько-нибудь длительного взаимодействия.

**Операционная невозможность**: длительные процессы не сочетаются с современными практиками эксплуатации. Облачные платформы перерабатывают виртуальные машины, перезапускают контейнеры и завершают бездействующие бессерверные процессы. Агент, неспособный пережить эти рутинные операции, операционно нежизнеспособен. Нам нужны агенты, которые умеют чекпоинтить состояние, приостанавливать исполнение, мигрировать между процессами и возобновляться бесшовно.

Ключевое понимание: экземпляры агентов должны быть переносимыми — способными перемещаться между процессами и машинами, сохраняя идентичность, состояние и незавершённые взаимодействия с пользователем, инструментами или другими агентами. Это требует фундаментального архитектурного разделения логического и физического существования агента.

Листинг 1.14 показывает грубую попытку решить эти проблемы через файловую персистентность:

```typescript
import OpenAI from "openai";
import fs from "fs/promises";
import path from "path";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const SYSTEM = "End your final answer with the symbol <EXIT>.";

interface ConversationData {
  messages: OpenAI.Chat.ChatCompletionMessageParam[];
}

async function loadConversation(
  identifier: string,
): Promise<OpenAI.Chat.ChatCompletionMessageParam[]> {
  const filePath = path.join(process.cwd(), `${identifier}.json`);

  try {
    const data = await fs.readFile(filePath, "utf-8");
    const conversation: ConversationData = JSON.parse(data);
    return conversation.messages;
  } catch (error) {
    // File doesn't exist, return new conversation with system message
    return [
      {
        role: "system",
        content: SYSTEM,
      },
    ];
  }
}

async function saveConversation(
  identifier: string,
  messages: OpenAI.Chat.ChatCompletionMessageParam[],
): Promise<void> {
  const filePath = path.join(process.cwd(), `${identifier}.json`);
  const conversation: ConversationData = { messages };
  await fs.writeFile(filePath, JSON.stringify(conversation, null, 2));
}

async function main() {
  // Parse command line arguments
  const args = process.argv.slice(2);

  if (args.length < 2) {
    console.error("Usage: ts-node index-4.ts <identifier> <prompt>");
    process.exit(1);
  }

  const identifier = args[0];
  const prompt = args.slice(1).join(" ");

  try {
    // Load existing conversation or create new one
    const messages = await loadConversation(identifier);

    // Add user message
    messages.push({role: "user", content: prompt});

    // Get completion from OpenAI
    const completion = await openai.chat.completions.create({
      model: "gpt-5",
      messages: messages
    });

    const answer = completion.choices[0]?.message?.content;

    if (answer) {
      // Add assistant response
      messages.push({role: "assistant", content: answer});

      // Save conversation
      await saveConversation(identifier, messages);

      // Output the response
      console.log("Assistant:", answer);
    } else {
      console.error("No response from OpenAI");
    }
  } catch (error) {
    console.error("An error occurred:", error);
    process.exit(1);
  }
}

// Run the main function
main();
```

<div className="listing-description">
  Листинг 1.14: Персистентное состояние беседы с использованием файлового хранилища
</div>

Эта наивная реализация подчёркивает, почему агентным системам нужна развитая инфраструктура для управления идентичностью, персистентности состояния и оркестрации процессов — фундаментальные задачи, которые нам предстоит решить, чтобы строить готовые к продакшну агентные приложения.

## 1.6 Итоги

* Токен — числовой идентификатор фрагмента текста.
* Токенизатор поддерживает двунаправленные отображения между токенами и фрагментами текста.
* Модель — упорядоченный набор параметров, назначающий вероятности токенам по заданному контексту.
* Модели характеризуются числом параметров (ёмкость хранения информации) и окном контекста (ёмкость одновременной обработки информации).
* Обучение создаёт или обновляет параметры модели из наборов данных — с нуля или через дообучение.
* Инференс применяет модель для предсказания следующего токена, используя контролируемую случайность для разнообразия выводов.
* Модели дополнения генерируют продолжение текста по подсказке.
* Модели диалога добавляют структуру ролей для поддержания многоходовой беседы.
* Модели вызова инструментов генерируют структурированные вызовы функций, но не исполняют их напрямую.
* Агенты комбинируют модели, инструменты и системные подсказки с устойчивым управлением состоянием.
* Экземпляры агентов поддерживают историю беседы, превращая stateless API в stateful системы.
* Построение продакшн-агентов требует развитой инфраструктуры для управления идентичностью, персистентности состояния и оркестрации процессов.
